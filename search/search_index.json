{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"chain-factory Chain Factory master repository of the Chain Factory project A framework to dispatch tasks fetched from an amqp queue to several worker nodes How to use components Redis RabbitMQ MongoDB api worker_node webui Backend start the dev backend using the prepared docker-compose file docker-compose up -d worker node To start a worker node you need to install the dependencies first and create a new directory with the workflows. pip install - r requirements . txt # copy the examples directory to the \"worker\" - directory cp - r framework / examples / worker / # then start the worker node using python . / main_worker . py If you are on a system with both python2 and python3 installed, you need to specify python3 instead of python as python on most systems is sym-linked with python2 How to register new tasks to the worker node To register new tasks to the worker node add either a new function together with the decorator @task_queue . task () def new_task () : print ( 'example' ) Or register the task using the decorator and using an imported function in an external file e.g. # file1.py class ExampleClass (): def example_task ( self ): print ( 'example' ) # main.py from file1 import ExampleClass example_instance = ExampleClass () task_queue . task ( 'example_task' )( example_instance . example_task ) Chain-Factory Architecture Reccomended Architecture Introduction Chain-Factory is per default installed on a kubernetes cluster. An example k3s cluster can be setup using the setup_k3s.sh script. Components MongoDB Cluster The MongoDB Database Server/Cluster is the persistent storage used to store the persistent state of the cluster. Rabbitmq The central broker, coordinating the distribution of tasks to the worker nodes. In case of a disaster recovery, the tasks, if not saved, can be restarted using a script in scripts/restart_tasks.sh or by manually getting a list of not yet finished tasks in mongodb and publishing them again to the broker by keeping the existing workflow id. Redis Redis is used to publish the heartbeat and enable the syncing of block lists. As redis is only used for some small and fast data objects, the amount of memory needed. can be kept very small. Rest-API The Rest-API is a http interface used to control the cluster. The Rest-API documentation is available at <rest-api-endpoint>/docs e.g. http://localhost:8000/docs . Authentication-API The Authentication-API is a container, which is written in golang, which enables the coupling of an microsoft active directory or any ldap directory server. Is needed to configure authentication at the rest-api as local accounts are not implemented, only idp integration, through the authentication-api. Worker (custom) Custom python script implementing the chain-factory framework. Consists of the initialization logic and all implemented tasks. Hashicorp Vault Hashicorp vault can be used to store sensitive information and retrieve them inside the tasks. WebUI The WebUI is a user interface usable from any modern web browser supporting javascript It connects to the rest-api to let operators control the chain-factory cluster. It consists of three sections Dashboard Shows the cluster status, how many nodes are there and how many of them are currently running Shows some workflow statistics Workflows Shows a list of all workflows ever run On the top of the table is a search bar, which is searchable through the following techniques Text Search: If you are entering plain text, the default is to search for the workflow name Regex Search: The workflow name can also be searched using regex (python re package syntax) Specific Search: If you prepent a specific operator (e.g. name:test_task), you can search specific sections in the workflow name tags namespace date (created date) arguments logs New Can be used to start a new task/workflow. Lists all currently available tasks. (if you stop a node, the tasks are not startable through the webui.) Installation The sample installation used for local developmental purposes only can be installed using the script install_k8s_resources.sh If you want to install the components in production you currently need to install it manually. But you can copy most of the lines in the install script to install it in production. You only need to remove the sections relevant for the loki/grafana stack and the samba active directory, which should act as a sample identity provider in the sample installation. The following components are needed for the production installation: MongoDB RabbitMQ Redis Authentication-API (To be able to use an ldap, keycloak or active directory server) Rest-API (To start workflows and control the cluster) Worker-Node (To execute the workflows) (WebUI, if needed) (if you already have a mongodb/RabbitMQ/Redis instance, you can skip those sections) The following steps expects to be executed from the chain-factory root of the repository. first define the base domain (needed, if you want to expose the rest-api and the web-ui through traefik) export BASE_DOMAIN_ENV=\"localhost\" MongoDB (skip if already there) install the mongodb community operator. kubectl apply -f ./k3s/mongodb/namespace.yml kubectl config set-context --current --namespace=mongodb-operator helm repo add mongodb https://mongodb.github.io/helm-charts helm repo update helm install community-operator mongodb/community-operator --namespace=mongodb-operator install the mongodb instance (replicaset) kubectl apply -f ./k3s/mongodb/mongodb.com_v1_mongodbcommunity_cr.yaml prefill the database with the example authentication configuration: ./scripts/provision_mongodb.sh Install Mongo-Express, if you want to have a web interface for managing the database instance - helm repo add cowboysysop https://cowboysysop.github.io/charts/ - helm repo update - helm install mongo-express cowboysysop/mongo-express --namespace=mongodb-operator -f ./k3s/mongodb/values_express.yaml - cat ./k3s/mongodb/ingress.yml | sed \"s/localhost/$BASE_DOMAIN_ENV/g\" | kubectl apply -f - Redis (skip if already there) Redis also deploys a web-interface for redis, called redis-express, which is accessible through traefik on redis.<domain> kubectl apply -f ./k3s/redis/namespace.yml kubectl config set-context --current --namespace=redis kubectl apply -f ./k3s/redis/configmap.yml kubectl apply -f ./k3s/redis/headless-service.yml kubectl apply -f ./k3s/redis/secrets.yml kubectl apply -f ./k3s/redis/statefulset.yml The ingress route for traefik: cat ./k3s/redis/ingress.yml | sed \"s/localhost/$BASE_DOMAIN_ENV/g\" | kubectl apply -f - RabbitMQ (skip if already there) kubectl apply -f ./k3s/rabbitmq/namespace.yml kubectl config set-context --current --namespace=rabbitmq kubectl apply -f ./k3s/rabbitmq/rbac.yml kubectl apply -f ./k3s/rabbitmq/headless-service.yml kubectl apply -f ./k3s/rabbitmq/configmap.yml kubectl apply -f ./k3s/rabbitmq/cookie.yml kubectl apply -f ./k3s/rabbitmq/admin-account.yml kubectl apply -f ./k3s/rabbitmq/statefulset.yml cat ./k3s/rabbitmq/ingress.yml | sed \"s/localhost/$BASE_DOMAIN_ENV/g\" | kubectl apply -f - Configuration Cleanup In k8s mode, there is a cron job, which automatically deletes oldest workflow/task logs. Per default it is configured to keep the workflows of the latest 90 days and delete everything else. The script inside the container uses a rest-api endpoint, which first retrieves all workflows in a given date range and then calls a rest-api endpoint to delete those workflows/workflow logs.","title":"chain-factory"},{"location":"#chain-factory","text":"Chain Factory master repository of the Chain Factory project A framework to dispatch tasks fetched from an amqp queue to several worker nodes","title":"chain-factory"},{"location":"#how-to-use","text":"","title":"How to use"},{"location":"#components","text":"Redis RabbitMQ MongoDB api worker_node webui","title":"components"},{"location":"#backend","text":"start the dev backend using the prepared docker-compose file docker-compose up -d","title":"Backend"},{"location":"#worker-node","text":"To start a worker node you need to install the dependencies first and create a new directory with the workflows. pip install - r requirements . txt # copy the examples directory to the \"worker\" - directory cp - r framework / examples / worker / # then start the worker node using python . / main_worker . py If you are on a system with both python2 and python3 installed, you need to specify python3 instead of python as python on most systems is sym-linked with python2","title":"worker node"},{"location":"#how-to-register-new-tasks-to-the-worker-node","text":"To register new tasks to the worker node add either a new function together with the decorator @task_queue . task () def new_task () : print ( 'example' ) Or register the task using the decorator and using an imported function in an external file e.g. # file1.py class ExampleClass (): def example_task ( self ): print ( 'example' ) # main.py from file1 import ExampleClass example_instance = ExampleClass () task_queue . task ( 'example_task' )( example_instance . example_task )","title":"How to register new tasks to the worker node"},{"location":"#chain-factory_1","text":"","title":"Chain-Factory"},{"location":"#architecture","text":"","title":"Architecture"},{"location":"#reccomended-architecture","text":"","title":"Reccomended Architecture"},{"location":"#introduction","text":"Chain-Factory is per default installed on a kubernetes cluster. An example k3s cluster can be setup using the setup_k3s.sh script.","title":"Introduction"},{"location":"#components_1","text":"MongoDB Cluster The MongoDB Database Server/Cluster is the persistent storage used to store the persistent state of the cluster. Rabbitmq The central broker, coordinating the distribution of tasks to the worker nodes. In case of a disaster recovery, the tasks, if not saved, can be restarted using a script in scripts/restart_tasks.sh or by manually getting a list of not yet finished tasks in mongodb and publishing them again to the broker by keeping the existing workflow id. Redis Redis is used to publish the heartbeat and enable the syncing of block lists. As redis is only used for some small and fast data objects, the amount of memory needed. can be kept very small. Rest-API The Rest-API is a http interface used to control the cluster. The Rest-API documentation is available at <rest-api-endpoint>/docs e.g. http://localhost:8000/docs . Authentication-API The Authentication-API is a container, which is written in golang, which enables the coupling of an microsoft active directory or any ldap directory server. Is needed to configure authentication at the rest-api as local accounts are not implemented, only idp integration, through the authentication-api. Worker (custom) Custom python script implementing the chain-factory framework. Consists of the initialization logic and all implemented tasks. Hashicorp Vault Hashicorp vault can be used to store sensitive information and retrieve them inside the tasks. WebUI The WebUI is a user interface usable from any modern web browser supporting javascript It connects to the rest-api to let operators control the chain-factory cluster. It consists of three sections Dashboard Shows the cluster status, how many nodes are there and how many of them are currently running Shows some workflow statistics Workflows Shows a list of all workflows ever run On the top of the table is a search bar, which is searchable through the following techniques Text Search: If you are entering plain text, the default is to search for the workflow name Regex Search: The workflow name can also be searched using regex (python re package syntax) Specific Search: If you prepent a specific operator (e.g. name:test_task), you can search specific sections in the workflow name tags namespace date (created date) arguments logs New Can be used to start a new task/workflow. Lists all currently available tasks. (if you stop a node, the tasks are not startable through the webui.)","title":"Components"},{"location":"#installation","text":"The sample installation used for local developmental purposes only can be installed using the script install_k8s_resources.sh If you want to install the components in production you currently need to install it manually. But you can copy most of the lines in the install script to install it in production. You only need to remove the sections relevant for the loki/grafana stack and the samba active directory, which should act as a sample identity provider in the sample installation. The following components are needed for the production installation: MongoDB RabbitMQ Redis Authentication-API (To be able to use an ldap, keycloak or active directory server) Rest-API (To start workflows and control the cluster) Worker-Node (To execute the workflows) (WebUI, if needed) (if you already have a mongodb/RabbitMQ/Redis instance, you can skip those sections) The following steps expects to be executed from the chain-factory root of the repository. first define the base domain (needed, if you want to expose the rest-api and the web-ui through traefik) export BASE_DOMAIN_ENV=\"localhost\" MongoDB (skip if already there) install the mongodb community operator. kubectl apply -f ./k3s/mongodb/namespace.yml kubectl config set-context --current --namespace=mongodb-operator helm repo add mongodb https://mongodb.github.io/helm-charts helm repo update helm install community-operator mongodb/community-operator --namespace=mongodb-operator install the mongodb instance (replicaset) kubectl apply -f ./k3s/mongodb/mongodb.com_v1_mongodbcommunity_cr.yaml prefill the database with the example authentication configuration: ./scripts/provision_mongodb.sh Install Mongo-Express, if you want to have a web interface for managing the database instance - helm repo add cowboysysop https://cowboysysop.github.io/charts/ - helm repo update - helm install mongo-express cowboysysop/mongo-express --namespace=mongodb-operator -f ./k3s/mongodb/values_express.yaml - cat ./k3s/mongodb/ingress.yml | sed \"s/localhost/$BASE_DOMAIN_ENV/g\" | kubectl apply -f - Redis (skip if already there) Redis also deploys a web-interface for redis, called redis-express, which is accessible through traefik on redis.<domain> kubectl apply -f ./k3s/redis/namespace.yml kubectl config set-context --current --namespace=redis kubectl apply -f ./k3s/redis/configmap.yml kubectl apply -f ./k3s/redis/headless-service.yml kubectl apply -f ./k3s/redis/secrets.yml kubectl apply -f ./k3s/redis/statefulset.yml The ingress route for traefik: cat ./k3s/redis/ingress.yml | sed \"s/localhost/$BASE_DOMAIN_ENV/g\" | kubectl apply -f - RabbitMQ (skip if already there) kubectl apply -f ./k3s/rabbitmq/namespace.yml kubectl config set-context --current --namespace=rabbitmq kubectl apply -f ./k3s/rabbitmq/rbac.yml kubectl apply -f ./k3s/rabbitmq/headless-service.yml kubectl apply -f ./k3s/rabbitmq/configmap.yml kubectl apply -f ./k3s/rabbitmq/cookie.yml kubectl apply -f ./k3s/rabbitmq/admin-account.yml kubectl apply -f ./k3s/rabbitmq/statefulset.yml cat ./k3s/rabbitmq/ingress.yml | sed \"s/localhost/$BASE_DOMAIN_ENV/g\" | kubectl apply -f -","title":"Installation"},{"location":"#configuration","text":"","title":"Configuration"},{"location":"#cleanup","text":"In k8s mode, there is a cron job, which automatically deletes oldest workflow/task logs. Per default it is configured to keep the workflows of the latest 90 days and delete everything else. The script inside the container uses a rest-api endpoint, which first retrieves all workflows in a given date range and then calls a rest-api endpoint to delete those workflows/workflow logs.","title":"Cleanup"},{"location":"contributing/","text":"Will be provided soon","title":"Contributing"},{"location":"contributing/#will-be-provided-soon","text":"","title":"Will be provided soon"},{"location":"examples/main/","text":"from logging import Formatter , StreamHandler , basicConfig , getLogger from os import getenv from sys import stdout from time import sleep from chain_factory.models.mongodb_models import Task from framework.src.chain_factory import ChainFactory # environment variables logging_level : str = getenv ( \"LOG_LEVEL\" , \"DEBUG\" ) cf_username : str = getenv ( 'CHAIN_FACTORY_USERNAME' , 'admin' ) cf_password : str = getenv ( 'CHAIN_FACTORY_PASSWORD' , 'admin' ) cf_endpoint : str = getenv ( 'CHAIN_FACTORY_ENDPOINT' , 'http://localhost:8005' ) cf_namespace : str = getenv ( 'CHAIN_FACTORY_NAMESPACE' , 'test01' ) # the namespace key can be retrieved through the chain-factory web interface # select a namespace # -> edit # -> rotate key # -> the new key will appear # -> copy it (the key will disappear when closing the modal) cf_namespace_key : str = getenv ( 'CHAIN_FACTORY_NAMESPACE_KEY' , '...' ) node_name = getenv ( 'HOSTNAME' , 'devnode01' ) # the default logging format logging_fmt = \" %(asctime)s , %(msecs)d %(levelname)-8s [ %(filename)s : %(lineno)d ] %(message)s \" # noqa: E501 try : root_logger = getLogger () root_logger . setLevel ( logging_level ) root_handler = StreamHandler ( stdout ) root_logger . addHandler ( root_handler ) root_handler . setFormatter ( Formatter ( logging_fmt )) except IndexError : basicConfig ( level = logging_level , format = logging_fmt ) # create the main TaskQueue object task_queue = ChainFactory ( username = cf_username , password = cf_password , endpoint = cf_endpoint , namespace = cf_namespace , namespace_key = cf_namespace_key , node_name = node_name ) task_queue . worker_count = 10 @task_queue . task () def test01 ( testvar01 : int ): print ( testvar01 ) print ( \"Hello World!\" ) @task_queue . task () def test02 (): print ( 'Test02<s>SECRET</s>' ) raise TypeError return test01 . s ( testvar01 = '01' ) # a next task can be started using the .s() method, this is the preferred way # noqa: E501 counter = 0 @task_queue . task ( 'simulate' ) def simulate ( times : int , i : int , exclude = [ 'i' ]): print ( \" [x] Received simulate task\" ) # print('times: ' + str(times)) # print('i' + str(i)) global counter counter = counter + 1 print ( 'counter: ' + str ( counter )) print ( type ( times )) # for i in range(0, times): # sleep(times) print ( \" [x] Done %d \" % i ) for x in range ( 0 , times ): print ( x ) sleep ( 1 ) return None # can also be ommitted @task_queue . task ( 'test_task' ) def test_task (): print ( \"test task\" ) print ( 'Test02<s>SECRET</s>' ) return 'simulate' , { 'i' : 0 , 'times' : 30 } # a task can also be returned by name # noqa: E501 @task_queue . task ( 'send_feedback' ) def send_feedback ( feedback ): print ( 'feedback: %s ' % ( feedback , )) return None @task_queue . task () def workflow_task (): print ( 'schedule next task: send_feedback' ) return Task ( name = 'send_feedback' , arguments = { 'feedback' : 'success' }) # a task can also be returned by Task object # noqa: E501 @task_queue . task () def failed_task ( failed_counter : int ): print ( 'Error, task failed!' ) failed_counter = failed_counter + 1 if failed_counter >= 3 : return None return False , { 'failed_counter' : failed_counter } # when returning False, the task will be retried # noqa: E501 # an example of a chained task @task_queue . task () def chained_task_01 (): print ( 'chained_task_01' ) return 'chained_task_02' , { 'arg1' : 'test01' } @task_queue . task () def chained_task_02 ( arg1 : str = 'test02' ): print ( 'chained_task_02' ) print ( 'arg1_chained_task_02: ' + arg1 ) if arg1 == 'test01' : print ( '...' ) return 'chained_task_03' , { 'arg2' : 'test' } else : return None @task_queue . task () def chained_task_03 ( arg2 : str ): print ( 'chained_task_03' ) return chained_task_02 , { 'arg1' : 'test02' } if __name__ == '__main__' : task_queue . run ()","title":"Main"},{"location":"private/client_pool/","text":"ClientPool source Methods: .init source . init ( redis_url : str , key_prefix : str , mongodb_url : str , loop : AbstractEventLoop ) initialises the redis client initialises the mongodb client .redis_client source . redis_client ( redis_url : str = 'default' , key_prefix : str = '' , loop : Optional [ AbstractEventLoop ] = None ) return a redis client specific to the given redis url if no redis url is given, return the default redis client if no default redis client exists, create a new one with the given redis url .close source . close () closes all the clients","title":"Client pool"},{"location":"private/client_pool/#_1","text":"","title":""},{"location":"private/client_pool/#clientpool","text":"source Methods:","title":"ClientPool"},{"location":"private/client_pool/#init","text":"source . init ( redis_url : str , key_prefix : str , mongodb_url : str , loop : AbstractEventLoop ) initialises the redis client initialises the mongodb client","title":".init"},{"location":"private/client_pool/#redis_client","text":"source . redis_client ( redis_url : str = 'default' , key_prefix : str = '' , loop : Optional [ AbstractEventLoop ] = None ) return a redis client specific to the given redis url if no redis url is given, return the default redis client if no default redis client exists, create a new one with the given redis url","title":".redis_client"},{"location":"private/client_pool/#close","text":"source . close () closes all the clients","title":".close"},{"location":"private/cluster_heartbeat/","text":"ClusterHeartbeat source ClusterHeartbeat ( namespace : str , node_name : str , client_pool : ClientPool , loop : AbstractEventLoop ) Methods: .start_heartbeat source . start_heartbeat () starts the heartbeat thread .stop_heartbeat source . stop_heartbeat () stops the heartbeat thread","title":"Cluster heartbeat"},{"location":"private/cluster_heartbeat/#_1","text":"","title":""},{"location":"private/cluster_heartbeat/#clusterheartbeat","text":"source ClusterHeartbeat ( namespace : str , node_name : str , client_pool : ClientPool , loop : AbstractEventLoop ) Methods:","title":"ClusterHeartbeat"},{"location":"private/cluster_heartbeat/#start_heartbeat","text":"source . start_heartbeat () starts the heartbeat thread","title":".start_heartbeat"},{"location":"private/cluster_heartbeat/#stop_heartbeat","text":"source . stop_heartbeat () stops the heartbeat thread","title":".stop_heartbeat"},{"location":"private/node_registration/","text":"NodeRegistration source NodeRegistration ( namespace : str , database : AIOEngine , node_name : str , task_handler : TaskHandler ) Methods: .register_tasks source . register_tasks () Registers all internally registered tasks in the database in the form: node_name/task_name .register source . register ()","title":"Node registration"},{"location":"private/node_registration/#_1","text":"","title":""},{"location":"private/node_registration/#noderegistration","text":"source NodeRegistration ( namespace : str , database : AIOEngine , node_name : str , task_handler : TaskHandler ) Methods:","title":"NodeRegistration"},{"location":"private/node_registration/#register_tasks","text":"source . register_tasks () Registers all internally registered tasks in the database in the form: node_name/task_name","title":".register_tasks"},{"location":"private/node_registration/#register","text":"source . register ()","title":".register"},{"location":"private/task_queue_handlers/","text":"TaskQueueHandlers source TaskQueueHandlers ( namespace : str , namespace_key : str , node_name : str , endpoint : str , username : str , password : str , worker_count : int , task_timeout : int , loop : Optional [ AbstractEventLoop ] = None ) Methods: .add_task source . add_task ( name : str , callback , repeat_on_timeout : bool = False ) .add_error_handler source . add_error_handler ( exc_type , callback : ErrorCallbackType ) .namespaced source . namespaced ( var : str ) .task_queue source . task_queue () .incoming_blocked_queue source . incoming_blocked_queue () .wait_queue source . wait_queue () .redis_client source . redis_client () .mongodb_client source . mongodb_client () .init source . init () Init all handlers -> wait handler -> incoming blocked handler -> wait blocked handler -> task handler -> cluster heartbeat .listen source . listen () Initialises the queue and starts listening .stop_heartbeat source . stop_heartbeat () .stop_node source . stop_node () .count_running_tasks source . count_running_tasks () .stop_listening source . stop_listening ()","title":"Task queue handlers"},{"location":"private/task_queue_handlers/#_1","text":"","title":""},{"location":"private/task_queue_handlers/#taskqueuehandlers","text":"source TaskQueueHandlers ( namespace : str , namespace_key : str , node_name : str , endpoint : str , username : str , password : str , worker_count : int , task_timeout : int , loop : Optional [ AbstractEventLoop ] = None ) Methods:","title":"TaskQueueHandlers"},{"location":"private/task_queue_handlers/#add_task","text":"source . add_task ( name : str , callback , repeat_on_timeout : bool = False )","title":".add_task"},{"location":"private/task_queue_handlers/#add_error_handler","text":"source . add_error_handler ( exc_type , callback : ErrorCallbackType )","title":".add_error_handler"},{"location":"private/task_queue_handlers/#namespaced","text":"source . namespaced ( var : str )","title":".namespaced"},{"location":"private/task_queue_handlers/#task_queue","text":"source . task_queue ()","title":".task_queue"},{"location":"private/task_queue_handlers/#incoming_blocked_queue","text":"source . incoming_blocked_queue ()","title":".incoming_blocked_queue"},{"location":"private/task_queue_handlers/#wait_queue","text":"source . wait_queue ()","title":".wait_queue"},{"location":"private/task_queue_handlers/#redis_client","text":"source . redis_client ()","title":".redis_client"},{"location":"private/task_queue_handlers/#mongodb_client","text":"source . mongodb_client ()","title":".mongodb_client"},{"location":"private/task_queue_handlers/#init","text":"source . init () Init all handlers -> wait handler -> incoming blocked handler -> wait blocked handler -> task handler -> cluster heartbeat","title":".init"},{"location":"private/task_queue_handlers/#listen","text":"source . listen () Initialises the queue and starts listening","title":".listen"},{"location":"private/task_queue_handlers/#stop_heartbeat","text":"source . stop_heartbeat ()","title":".stop_heartbeat"},{"location":"private/task_queue_handlers/#stop_node","text":"source . stop_node ()","title":".stop_node"},{"location":"private/task_queue_handlers/#count_running_tasks","text":"source . count_running_tasks ()","title":".count_running_tasks"},{"location":"private/task_queue_handlers/#stop_listening","text":"source . stop_listening ()","title":".stop_listening"},{"location":"private/credentials/credentials_model/","text":"RabbitMQCredentials source RabbitMQCredentials () RedisCredentials source RedisCredentials () MongoDBCredentials source MongoDBCredentials () ManagementCredentials source ManagementCredentials () ManagementCredentialsCollection source ManagementCredentialsCollection ()","title":"Credentials model"},{"location":"private/credentials/credentials_model/#_1","text":"","title":""},{"location":"private/credentials/credentials_model/#rabbitmqcredentials","text":"source RabbitMQCredentials ()","title":"RabbitMQCredentials"},{"location":"private/credentials/credentials_model/#rediscredentials","text":"source RedisCredentials ()","title":"RedisCredentials"},{"location":"private/credentials/credentials_model/#mongodbcredentials","text":"source MongoDBCredentials ()","title":"MongoDBCredentials"},{"location":"private/credentials/credentials_model/#managementcredentials","text":"source ManagementCredentials ()","title":"ManagementCredentials"},{"location":"private/credentials/credentials_model/#managementcredentialscollection","text":"source ManagementCredentialsCollection ()","title":"ManagementCredentialsCollection"},{"location":"private/credentials/credentials_pool/","text":"CredentialsPool source CredentialsPool ( endpoint : str , username : str , password : str , namespaces : Dict [ str , str ] = {} ) CredentialsPool is a class that is responsible for managing the database credentials for a specific namespace. Can be retrieved using the credentials and the namespace key. Methods: .init source . init () .get_credentials source . get_credentials ( namespace : str , key : str = '' ) Get the credentials for the namespace. .update_credentials source . update_credentials () Update the credentials internally for the namespace.","title":"Credentials pool"},{"location":"private/credentials/credentials_pool/#_1","text":"","title":""},{"location":"private/credentials/credentials_pool/#credentialspool","text":"source CredentialsPool ( endpoint : str , username : str , password : str , namespaces : Dict [ str , str ] = {} ) CredentialsPool is a class that is responsible for managing the database credentials for a specific namespace. Can be retrieved using the credentials and the namespace key. Methods:","title":"CredentialsPool"},{"location":"private/credentials/credentials_pool/#init","text":"source . init ()","title":".init"},{"location":"private/credentials/credentials_pool/#get_credentials","text":"source . get_credentials ( namespace : str , key : str = '' ) Get the credentials for the namespace.","title":".get_credentials"},{"location":"private/credentials/credentials_pool/#update_credentials","text":"source . update_credentials () Update the credentials internally for the namespace.","title":".update_credentials"},{"location":"private/credentials/credentials_retriever/","text":"CredentialsRetriever source CredentialsRetriever ( endpoint : str , namespace : str , username : str , password : str , key : str ) Retrieve database credentials from rest api Methods: .init source . init () The init method is used to initialize the class as the __init__ method does not work with async .mongodb source . mongodb () get MongoDB credentials from credentials .redis source . redis () get redis credentials from credentials .redis_prefix source . redis_prefix () get redis prefix from credentials .rabbitmq source . rabbitmq () get rabbitmq credentials from credentials .get_jwe_token source . get_jwe_token ( username , password ) send login request to internal rest-api on /api/login .a_get_jwe_token source . a_get_jwe_token ( username , password ) .get_credentials source . get_credentials () retrieve namespace credentials from internal rest-api on /api/v1/credentials using login token and namespace/namespace-key (which is used to decrypt the credentials created on namespace key rotation)","title":"Credentials retriever"},{"location":"private/credentials/credentials_retriever/#_1","text":"","title":""},{"location":"private/credentials/credentials_retriever/#credentialsretriever","text":"source CredentialsRetriever ( endpoint : str , namespace : str , username : str , password : str , key : str ) Retrieve database credentials from rest api Methods:","title":"CredentialsRetriever"},{"location":"private/credentials/credentials_retriever/#init","text":"source . init () The init method is used to initialize the class as the __init__ method does not work with async","title":".init"},{"location":"private/credentials/credentials_retriever/#mongodb","text":"source . mongodb () get MongoDB credentials from credentials","title":".mongodb"},{"location":"private/credentials/credentials_retriever/#redis","text":"source . redis () get redis credentials from credentials","title":".redis"},{"location":"private/credentials/credentials_retriever/#redis_prefix","text":"source . redis_prefix () get redis prefix from credentials","title":".redis_prefix"},{"location":"private/credentials/credentials_retriever/#rabbitmq","text":"source . rabbitmq () get rabbitmq credentials from credentials","title":".rabbitmq"},{"location":"private/credentials/credentials_retriever/#get_jwe_token","text":"source . get_jwe_token ( username , password ) send login request to internal rest-api on /api/login","title":".get_jwe_token"},{"location":"private/credentials/credentials_retriever/#a_get_jwe_token","text":"source . a_get_jwe_token ( username , password )","title":".a_get_jwe_token"},{"location":"private/credentials/credentials_retriever/#get_credentials","text":"source . get_credentials () retrieve namespace credentials from internal rest-api on /api/v1/credentials using login token and namespace/namespace-key (which is used to decrypt the credentials created on namespace key rotation)","title":".get_credentials"},{"location":"private/task_handler/argument_excluder/","text":"ArgumentExcluder source ArgumentExcluder ( arguments ) This class is used to exclude arguments from the arguments dictionary, before saving the task in the database If the arguments dictionary contains an \"exclude\" key, the values of this key will be excluded from the arguments Methods: .exclude source . exclude () Exclude the arguments from the arguments dictionary","title":"Argument excluder"},{"location":"private/task_handler/argument_excluder/#_1","text":"","title":""},{"location":"private/task_handler/argument_excluder/#argumentexcluder","text":"source ArgumentExcluder ( arguments ) This class is used to exclude arguments from the arguments dictionary, before saving the task in the database If the arguments dictionary contains an \"exclude\" key, the values of this key will be excluded from the arguments Methods:","title":"ArgumentExcluder"},{"location":"private/task_handler/argument_excluder/#exclude","text":"source . exclude () Exclude the arguments from the arguments dictionary","title":".exclude"},{"location":"private/task_handler/bytes_io_wrapper/","text":"BytesIOWrapper source BytesIOWrapper ( task_id : str , workflow_id : str , mongodb_database : AIOEngine , loop : AbstractEventLoop ) Wrapper for BytesIO to write to stdout and mongodb Methods: .read source . read ( size : Optional [ int ] = ... ) .write source . write ( b : Union [ bytes , bytearray ] ) .remove_secrets source . remove_secrets ( string : str )","title":"Bytes io wrapper"},{"location":"private/task_handler/bytes_io_wrapper/#_1","text":"","title":""},{"location":"private/task_handler/bytes_io_wrapper/#bytesiowrapper","text":"source BytesIOWrapper ( task_id : str , workflow_id : str , mongodb_database : AIOEngine , loop : AbstractEventLoop ) Wrapper for BytesIO to write to stdout and mongodb Methods:","title":"BytesIOWrapper"},{"location":"private/task_handler/bytes_io_wrapper/#read","text":"source . read ( size : Optional [ int ] = ... )","title":".read"},{"location":"private/task_handler/bytes_io_wrapper/#write","text":"source . write ( b : Union [ bytes , bytearray ] )","title":".write"},{"location":"private/task_handler/bytes_io_wrapper/#remove_secrets","text":"source . remove_secrets ( string : str )","title":".remove_secrets"},{"location":"private/task_handler/list_handler/","text":"ListHandler source ListHandler ( list_name : str , redis_client : RedisClient ) Wrapper class to manage a list in redis in form of a json document Methods: .parse_json source . parse_json ( body : bytes ) Decode the redis data to a utf-8 string, parse the string to json and check, if the data structure fo the parsed object is valid .clear source . clear () Clear the redis list .init source . init () Initialise the redis list with an empty list if the list doesn't exist yet .add source . add ( list_item : ListItem ) Add an entry to the redis list .remove source . remove ( list_item : ListItem ) Remove an entry from the list .get source . get () get the list","title":"List handler"},{"location":"private/task_handler/list_handler/#_1","text":"","title":""},{"location":"private/task_handler/list_handler/#listhandler","text":"source ListHandler ( list_name : str , redis_client : RedisClient ) Wrapper class to manage a list in redis in form of a json document Methods:","title":"ListHandler"},{"location":"private/task_handler/list_handler/#parse_json","text":"source . parse_json ( body : bytes ) Decode the redis data to a utf-8 string, parse the string to json and check, if the data structure fo the parsed object is valid","title":".parse_json"},{"location":"private/task_handler/list_handler/#clear","text":"source . clear () Clear the redis list","title":".clear"},{"location":"private/task_handler/list_handler/#init","text":"source . init () Initialise the redis list with an empty list if the list doesn't exist yet","title":".init"},{"location":"private/task_handler/list_handler/#add","text":"source . add ( list_item : ListItem ) Add an entry to the redis list","title":".add"},{"location":"private/task_handler/list_handler/#remove","text":"source . remove ( list_item : ListItem ) Remove an entry from the list","title":".remove"},{"location":"private/task_handler/list_handler/#get","text":"source . get () get the list","title":".get"},{"location":"private/task_handler/parse_catcher/","text":"parse_catcher source . parse_catcher ( errors : Tuple [ Type [ Exception ], ... ] = ( Exception , ) ) Catches exceptions and prints them to stdout. Returns None if an exception is caught Used in QueueHandler and ListHandler","title":"Parse catcher"},{"location":"private/task_handler/parse_catcher/#_1","text":"","title":""},{"location":"private/task_handler/parse_catcher/#parse_catcher","text":"source . parse_catcher ( errors : Tuple [ Type [ Exception ], ... ] = ( Exception , ) ) Catches exceptions and prints them to stdout. Returns None if an exception is caught Used in QueueHandler and ListHandler","title":"parse_catcher"},{"location":"private/task_handler/queue_handler/","text":"QueueHandler source Base Class for the TaskQueue, handles the rabbitmq task queue dispatch logic Methods: .init source . init ( url : str , queue_name : str , loop : AbstractEventLoop ) Separate init logic to be able to use lazy initialisation .stop_listening source . stop_listening () .close source . close () .listen source . listen () starts listening on the queue .reschedule source . reschedule ( message : Message ) Reschedules or rather rejects the message ._now source . _now () returns the current time with timezone .send_to_queue source . send_to_queue ( task : Task , rabbitmq : Union [ RabbitMQ , None ] ) Send a task to the specified queue .ack source . ack ( message : Message ) Acknowledges the specified message .nack source . nack ( message : Message ) Rejects the specified message .on_task source . on_task ( task : Task , message : Message ) abstract method for the overriding clas, will be invoked, when a new task comes in ._parse_json source . _parse_json ( body : str ) ._parse_json source . _parse_json ( body : str )","title":"Queue handler"},{"location":"private/task_handler/queue_handler/#_1","text":"","title":""},{"location":"private/task_handler/queue_handler/#queuehandler","text":"source Base Class for the TaskQueue, handles the rabbitmq task queue dispatch logic Methods:","title":"QueueHandler"},{"location":"private/task_handler/queue_handler/#init","text":"source . init ( url : str , queue_name : str , loop : AbstractEventLoop ) Separate init logic to be able to use lazy initialisation","title":".init"},{"location":"private/task_handler/queue_handler/#stop_listening","text":"source . stop_listening ()","title":".stop_listening"},{"location":"private/task_handler/queue_handler/#close","text":"source . close ()","title":".close"},{"location":"private/task_handler/queue_handler/#listen","text":"source . listen () starts listening on the queue","title":".listen"},{"location":"private/task_handler/queue_handler/#reschedule","text":"source . reschedule ( message : Message ) Reschedules or rather rejects the message","title":".reschedule"},{"location":"private/task_handler/queue_handler/#_now","text":"source . _now () returns the current time with timezone","title":"._now"},{"location":"private/task_handler/queue_handler/#send_to_queue","text":"source . send_to_queue ( task : Task , rabbitmq : Union [ RabbitMQ , None ] ) Send a task to the specified queue","title":".send_to_queue"},{"location":"private/task_handler/queue_handler/#ack","text":"source . ack ( message : Message ) Acknowledges the specified message","title":".ack"},{"location":"private/task_handler/queue_handler/#nack","text":"source . nack ( message : Message ) Rejects the specified message","title":".nack"},{"location":"private/task_handler/queue_handler/#on_task","text":"source . on_task ( task : Task , message : Message ) abstract method for the overriding clas, will be invoked, when a new task comes in","title":".on_task"},{"location":"private/task_handler/queue_handler/#_parse_json","text":"source . _parse_json ( body : str )","title":"._parse_json"},{"location":"private/task_handler/queue_handler/#_parse_json_1","text":"source . _parse_json ( body : str )","title":"._parse_json"},{"location":"private/task_handler/task_handler/","text":"TaskHandler source TaskHandler ( namespace : str , node_name : str ) Methods: .init source . init ( mongodb_client : AIOEngine , redis_client : RedisClient , queue_name : str , wait_queue_name : str , blocked_queue_name : str , loop : AbstractEventLoop , rabbitmq_url : str ) Initialize the task handler there is this extra init function, because the init function does not support async functions .update_task_timeout source . update_task_timeout () Update the task timeout value for all registered tasks .update_error_handlers source . update_error_handlers () Update the error handlers for all registered tasks .check_rejected_task source . check_rejected_task ( task : Task , message : Message ) Checks if the task has been rejected too often .on_task source . on_task ( task : Task , message : Message ) The callback function, which will be called from the rabbitmq library It deserializes the amqp message and then checks, if the requested taks is registered and calls it. If the task name is on the blocklist, it will be rejected, rescheduled and then wait for some time Returns either None or a new task .add_task source . add_task ( name : str , callback : CallbackType , repeat_on_timeout : bool ) Register a new task/task function .add_error_handler source . add_error_handler ( exc_type : Type [ Exception ], callback : ErrorCallbackType ) Register a new error handler :param callback: the callback function :type callback: Callable[[Task, Exception], None] .clear_error_handlers source . clear_error_handlers () Clear all registered error handlers .add_schedule_task_shortcut source . add_schedule_task_shortcut ( name : str , callback : CallbackType ) Add a function to the registered function named .s() to schedule the function with or without arguments .task_set_redis_client source . task_set_redis_client ( redis_client : RedisClient ) Set the redis client for all registered tasks","title":"Task handler"},{"location":"private/task_handler/task_handler/#_1","text":"","title":""},{"location":"private/task_handler/task_handler/#taskhandler","text":"source TaskHandler ( namespace : str , node_name : str ) Methods:","title":"TaskHandler"},{"location":"private/task_handler/task_handler/#init","text":"source . init ( mongodb_client : AIOEngine , redis_client : RedisClient , queue_name : str , wait_queue_name : str , blocked_queue_name : str , loop : AbstractEventLoop , rabbitmq_url : str ) Initialize the task handler there is this extra init function, because the init function does not support async functions","title":".init"},{"location":"private/task_handler/task_handler/#update_task_timeout","text":"source . update_task_timeout () Update the task timeout value for all registered tasks","title":".update_task_timeout"},{"location":"private/task_handler/task_handler/#update_error_handlers","text":"source . update_error_handlers () Update the error handlers for all registered tasks","title":".update_error_handlers"},{"location":"private/task_handler/task_handler/#check_rejected_task","text":"source . check_rejected_task ( task : Task , message : Message ) Checks if the task has been rejected too often","title":".check_rejected_task"},{"location":"private/task_handler/task_handler/#on_task","text":"source . on_task ( task : Task , message : Message ) The callback function, which will be called from the rabbitmq library It deserializes the amqp message and then checks, if the requested taks is registered and calls it. If the task name is on the blocklist, it will be rejected, rescheduled and then wait for some time Returns either None or a new task","title":".on_task"},{"location":"private/task_handler/task_handler/#add_task","text":"source . add_task ( name : str , callback : CallbackType , repeat_on_timeout : bool ) Register a new task/task function","title":".add_task"},{"location":"private/task_handler/task_handler/#add_error_handler","text":"source . add_error_handler ( exc_type : Type [ Exception ], callback : ErrorCallbackType ) Register a new error handler :param callback: the callback function :type callback: Callable[[Task, Exception], None]","title":".add_error_handler"},{"location":"private/task_handler/task_handler/#clear_error_handlers","text":"source . clear_error_handlers () Clear all registered error handlers","title":".clear_error_handlers"},{"location":"private/task_handler/task_handler/#add_schedule_task_shortcut","text":"source . add_schedule_task_shortcut ( name : str , callback : CallbackType ) Add a function to the registered function named .s() to schedule the function with or without arguments","title":".add_schedule_task_shortcut"},{"location":"private/task_handler/task_handler/#task_set_redis_client","text":"source . task_set_redis_client ( redis_client : RedisClient ) Set the redis client for all registered tasks","title":".task_set_redis_client"},{"location":"private/task_runner/control_thread/","text":"ControlThread source ControlThread ( workflow_id : str , control_actions : Dict [ str , Callable ], redis_client : RedisClient , control_channel : str , thread_name : str = '' ) The thread which handles the control messages Can be interrupted by calling stop() Methods: .stop source . stop () .run_async source . run_async ( loop : Optional [ AbstractEventLoop ] = None )","title":"Control thread"},{"location":"private/task_runner/control_thread/#_1","text":"","title":""},{"location":"private/task_runner/control_thread/#controlthread","text":"source ControlThread ( workflow_id : str , control_actions : Dict [ str , Callable ], redis_client : RedisClient , control_channel : str , thread_name : str = '' ) The thread which handles the control messages Can be interrupted by calling stop() Methods:","title":"ControlThread"},{"location":"private/task_runner/control_thread/#stop","text":"source . stop ()","title":".stop"},{"location":"private/task_runner/control_thread/#run_async","text":"source . run_async ( loop : Optional [ AbstractEventLoop ] = None )","title":".run_async"},{"location":"private/task_runner/task_control_thread/","text":"TaskControlThread source TaskControlThread ( workflow_id : str , task_thread : TaskThread , redis_client : RedisClient , namespace : str ) TaskControlThread is a thread that listens to a redis channel for control messages. It is used to stop or abort a task. ControlThread is a base class that is used to implement the redis broadcast listener.","title":"Task control thread"},{"location":"private/task_runner/task_control_thread/#_1","text":"","title":""},{"location":"private/task_runner/task_control_thread/#taskcontrolthread","text":"source TaskControlThread ( workflow_id : str , task_thread : TaskThread , redis_client : RedisClient , namespace : str ) TaskControlThread is a thread that listens to a redis channel for control messages. It is used to stop or abort a task. ControlThread is a base class that is used to implement the redis broadcast listener.","title":"TaskControlThread"},{"location":"private/task_runner/task_runner/","text":"TaskRunner source TaskRunner ( name : str , callback : CallbackType , namespace : str ) Methods: .set_redis_client source . set_redis_client ( redis_client : RedisClient ) .update_task_timeout source . update_task_timeout ( task_timeout : int ) .update_error_handlers source . update_error_handlers ( error_handlers : ErrorCallbackMappingType ) .update_task_repeat_on_timeout source . update_task_repeat_on_timeout ( task_repeat_on_timeout : bool ) .task_repeat_on_timeout source . task_repeat_on_timeout () .update_namespace source . update_namespace ( namespace : str ) .running_workflows source . running_workflows () .run source . run ( workflow : Optional [ Workflow ], task : Task , buffer : BytesIO , loop : Optional [ AbstractEventLoop ] = get_event_loop () ) ._parse_task_output source . _parse_task_output ( task_result : FreeTaskReturnType , old_arguments : ArgumentType ) Check, if new parameters have been returned, to be able to reschedule the same task with changed parameters Returns the result of the task and the arguments, either the default arguments or the newly returned arguments .convert_arguments source . convert_arguments ( arguments : ArgumentType ) .abort source . abort ( workflow_id : str ) .stop source . stop ( workflow_id : str )","title":"Task runner"},{"location":"private/task_runner/task_runner/#_1","text":"","title":""},{"location":"private/task_runner/task_runner/#taskrunner","text":"source TaskRunner ( name : str , callback : CallbackType , namespace : str ) Methods:","title":"TaskRunner"},{"location":"private/task_runner/task_runner/#set_redis_client","text":"source . set_redis_client ( redis_client : RedisClient )","title":".set_redis_client"},{"location":"private/task_runner/task_runner/#update_task_timeout","text":"source . update_task_timeout ( task_timeout : int )","title":".update_task_timeout"},{"location":"private/task_runner/task_runner/#update_error_handlers","text":"source . update_error_handlers ( error_handlers : ErrorCallbackMappingType )","title":".update_error_handlers"},{"location":"private/task_runner/task_runner/#update_task_repeat_on_timeout","text":"source . update_task_repeat_on_timeout ( task_repeat_on_timeout : bool )","title":".update_task_repeat_on_timeout"},{"location":"private/task_runner/task_runner/#task_repeat_on_timeout","text":"source . task_repeat_on_timeout ()","title":".task_repeat_on_timeout"},{"location":"private/task_runner/task_runner/#update_namespace","text":"source . update_namespace ( namespace : str )","title":".update_namespace"},{"location":"private/task_runner/task_runner/#running_workflows","text":"source . running_workflows ()","title":".running_workflows"},{"location":"private/task_runner/task_runner/#run","text":"source . run ( workflow : Optional [ Workflow ], task : Task , buffer : BytesIO , loop : Optional [ AbstractEventLoop ] = get_event_loop () )","title":".run"},{"location":"private/task_runner/task_runner/#_parse_task_output","text":"source . _parse_task_output ( task_result : FreeTaskReturnType , old_arguments : ArgumentType ) Check, if new parameters have been returned, to be able to reschedule the same task with changed parameters Returns the result of the task and the arguments, either the default arguments or the newly returned arguments","title":"._parse_task_output"},{"location":"private/task_runner/task_runner/#convert_arguments","text":"source . convert_arguments ( arguments : ArgumentType )","title":".convert_arguments"},{"location":"private/task_runner/task_runner/#abort","text":"source . abort ( workflow_id : str )","title":".abort"},{"location":"private/task_runner/task_runner/#stop","text":"source . stop ( workflow_id : str )","title":".stop"},{"location":"private/task_runner/task_thread/","text":"TaskThread source TaskThread ( name : str , callback : Callable , arguments , buffer : BytesIO , error_handlers : ErrorCallbackMappingType , workflow : Optional [ Workflow ], task : Task ) The thread which actually runs the task the output of stdio will be redirected to a buffer and later uploaded to the mongodb database Methods: .run source . run () .try_error_handler source . try_error_handler ( e ) .stop source . stop () .abort source . abort () .abort_timeout source . abort_timeout ()","title":"Task thread"},{"location":"private/task_runner/task_thread/#_1","text":"","title":""},{"location":"private/task_runner/task_thread/#taskthread","text":"source TaskThread ( name : str , callback : Callable , arguments , buffer : BytesIO , error_handlers : ErrorCallbackMappingType , workflow : Optional [ Workflow ], task : Task ) The thread which actually runs the task the output of stdio will be redirected to a buffer and later uploaded to the mongodb database Methods:","title":"TaskThread"},{"location":"private/task_runner/task_thread/#run","text":"source . run ()","title":".run"},{"location":"private/task_runner/task_thread/#try_error_handler","text":"source . try_error_handler ( e )","title":".try_error_handler"},{"location":"private/task_runner/task_thread/#stop","text":"source . stop ()","title":".stop"},{"location":"private/task_runner/task_thread/#abort","text":"source . abort ()","title":".abort"},{"location":"private/task_runner/task_thread/#abort_timeout","text":"source . abort_timeout ()","title":".abort_timeout"},{"location":"public/chain_factory/","text":"ChainFactory source ChainFactory ( endpoint : str , username : str , password : str , node_name : str , namespace : str = default_namespace , namespace_key : str = default_namespace_key , worker_count : int = default_worker_count , task_timeout : int = default_task_timeout , task_repeat_on_timeout : bool = default_task_repeat_on_timeout ) Main Class for the chain-factory framework This class is used to initialize the framework by creating a new instance of the class to register tasks and to start listening Methods: .task source . task ( name : str = '' , repeat_on_timeout : bool = default_task_repeat_on_timeout ) Decorator to register a new task in the framework Registers a new task in the framework internally using the function name as the task name using the function as the task handler, which will be wrapped internally in a TaskRunner class also adds a special .s method to the function, which can be used to start the function as a task from inside another task (for chaining of tasks) registration in mongodb will be done during the initialisation phase .add_task source . add_task ( func , name : str = '' , repeat_on_timeout : bool = default_task_repeat_on_timeout ) Method to add tasks, which cannot be added using the decorator Calls the task decorator .add_error_context source . add_error_context () Decorator to add workflow context to a task Adds the workflow context to the task .shutdown source . shutdown () Shuts down the framework .add_error_handler source . add_error_handler ( exc_type : Type [ Exception ], func : ErrorCallbackType ) Adds an error handler to the framework .listen source . listen ( loop : Optional [ AbstractEventLoop ] = None ) Initialises the queue and starts listening Will be invoked by the run method .run source . run ( loop : Optional [ AbstractEventLoop ] = None ) Runs the task queue: Starts a new event loop or uses a provided one Starts listening for tasks and stops the event loop on keyboard interrupt","title":"Chain factory"},{"location":"public/chain_factory/#_1","text":"","title":""},{"location":"public/chain_factory/#chainfactory","text":"source ChainFactory ( endpoint : str , username : str , password : str , node_name : str , namespace : str = default_namespace , namespace_key : str = default_namespace_key , worker_count : int = default_worker_count , task_timeout : int = default_task_timeout , task_repeat_on_timeout : bool = default_task_repeat_on_timeout ) Main Class for the chain-factory framework This class is used to initialize the framework by creating a new instance of the class to register tasks and to start listening Methods:","title":"ChainFactory"},{"location":"public/chain_factory/#task","text":"source . task ( name : str = '' , repeat_on_timeout : bool = default_task_repeat_on_timeout ) Decorator to register a new task in the framework Registers a new task in the framework internally using the function name as the task name using the function as the task handler, which will be wrapped internally in a TaskRunner class also adds a special .s method to the function, which can be used to start the function as a task from inside another task (for chaining of tasks) registration in mongodb will be done during the initialisation phase","title":".task"},{"location":"public/chain_factory/#add_task","text":"source . add_task ( func , name : str = '' , repeat_on_timeout : bool = default_task_repeat_on_timeout ) Method to add tasks, which cannot be added using the decorator Calls the task decorator","title":".add_task"},{"location":"public/chain_factory/#add_error_context","text":"source . add_error_context () Decorator to add workflow context to a task Adds the workflow context to the task","title":".add_error_context"},{"location":"public/chain_factory/#shutdown","text":"source . shutdown () Shuts down the framework","title":".shutdown"},{"location":"public/chain_factory/#add_error_handler","text":"source . add_error_handler ( exc_type : Type [ Exception ], func : ErrorCallbackType ) Adds an error handler to the framework","title":".add_error_handler"},{"location":"public/chain_factory/#listen","text":"source . listen ( loop : Optional [ AbstractEventLoop ] = None ) Initialises the queue and starts listening Will be invoked by the run method","title":".listen"},{"location":"public/chain_factory/#run","text":"source . run ( loop : Optional [ AbstractEventLoop ] = None ) Runs the task queue: Starts a new event loop or uses a provided one Starts listening for tasks and stops the event loop on keyboard interrupt","title":".run"},{"location":"public/api/credentials/","text":"create_credentials source . create_credentials ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), redis_client : Redis = Depends ( get_redis_client ), rabbitmq_management_api : ManagementApi = Depends ( get_rabbitmq_management_api ), namespace_obj : Namespace = Depends ( get_allowed_namespace ) ) Create credentials for a namespace. Encrypt the credentials and return the password to retrieve the credentials. Return an error if the namespace does not exist Raises HTTPException : Raises exception if credentials could not be created HTTPException : Raises exception if namespace does not exist or user has no access Returns ManagementCredentials(Object) get_credentials source . get_credentials ( namespace : str , key : str , database : AIOEngine = Depends ( get_odm_session ) ) Get credentials for the current user. 1. check, if the current user has access to the requested namespace 2. check, if the credentials are already stored in the database 3. if not, create new credentials and store them in the database 4. the credentials are only valid a limited amount of time 5. return the credentials","title":"Credentials"},{"location":"public/api/credentials/#_1","text":"","title":""},{"location":"public/api/credentials/#create_credentials","text":"source . create_credentials ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), redis_client : Redis = Depends ( get_redis_client ), rabbitmq_management_api : ManagementApi = Depends ( get_rabbitmq_management_api ), namespace_obj : Namespace = Depends ( get_allowed_namespace ) ) Create credentials for a namespace. Encrypt the credentials and return the password to retrieve the credentials. Return an error if the namespace does not exist Raises HTTPException : Raises exception if credentials could not be created HTTPException : Raises exception if namespace does not exist or user has no access Returns ManagementCredentials(Object)","title":"create_credentials"},{"location":"public/api/credentials/#get_credentials","text":"source . get_credentials ( namespace : str , key : str , database : AIOEngine = Depends ( get_odm_session ) ) Get credentials for the current user. 1. check, if the current user has access to the requested namespace 2. check, if the credentials are already stored in the database 3. if not, create new credentials and store them in the database 4. the credentials are only valid a limited amount of time 5. return the credentials","title":"get_credentials"},{"location":"public/api/namespace/","text":"namespaces source . namespaces ( database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ) ) disabled_namespaces source . disabled_namespaces ( database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ) ) create_namespace source . create_namespace ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), breakglass_username : str = Depends ( get_breakglass_username ), breakglass_domain : str = Depends ( get_breakglass_domain ) ) allow_user_to_namespace source . allow_user_to_namespace ( namespace : str , username : str , current_user : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) ) remove_user_from_namespace source . remove_user_from_namespace ( namespace : str , username : str , current_user : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) ) disable_namespace source . disable_namespace ( namespace : str , username : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) ) delete_namespace source . delete_namespace ( namespace : str , username : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ), redis_client : Redis = Depends ( get_redis_client ), rabbitmq_management_api : ManagementApi = Depends ( get_rabbitmq_management_api ) ) enable_namespace source . enable_namespace ( namespace : str , username : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) ) rename_namespace source . rename_namespace ( namespace : str , new_namespace : str , username : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) )","title":"Namespace"},{"location":"public/api/namespace/#_1","text":"","title":""},{"location":"public/api/namespace/#namespaces","text":"source . namespaces ( database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ) )","title":"namespaces"},{"location":"public/api/namespace/#disabled_namespaces","text":"source . disabled_namespaces ( database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ) )","title":"disabled_namespaces"},{"location":"public/api/namespace/#create_namespace","text":"source . create_namespace ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), breakglass_username : str = Depends ( get_breakglass_username ), breakglass_domain : str = Depends ( get_breakglass_domain ) )","title":"create_namespace"},{"location":"public/api/namespace/#allow_user_to_namespace","text":"source . allow_user_to_namespace ( namespace : str , username : str , current_user : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) )","title":"allow_user_to_namespace"},{"location":"public/api/namespace/#remove_user_from_namespace","text":"source . remove_user_from_namespace ( namespace : str , username : str , current_user : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) )","title":"remove_user_from_namespace"},{"location":"public/api/namespace/#disable_namespace","text":"source . disable_namespace ( namespace : str , username : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) )","title":"disable_namespace"},{"location":"public/api/namespace/#delete_namespace","text":"source . delete_namespace ( namespace : str , username : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ), redis_client : Redis = Depends ( get_redis_client ), rabbitmq_management_api : ManagementApi = Depends ( get_rabbitmq_management_api ) )","title":"delete_namespace"},{"location":"public/api/namespace/#enable_namespace","text":"source . enable_namespace ( namespace : str , username : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) )","title":"enable_namespace"},{"location":"public/api/namespace/#rename_namespace","text":"source . rename_namespace ( namespace : str , new_namespace : str , username : str = Depends ( get_username ), database : AIOEngine = Depends ( get_odm_session ) )","title":"rename_namespace"},{"location":"public/api/node/","text":"stop_node source . stop_node ( namespace : str , node_name : str , redis_client : Redis = Depends ( get_redis_client ), database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), namespaces : List [ Namespace ] = Depends ( get_allowed_namespaces ) ) node_metrics source . node_metrics ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : Redis = Depends ( get_redis_client ), namespaces : List [ str ] = Depends ( get_allowed_namespaces ), username : str = Depends ( get_username ) ) delete_node source . delete_node ( node_name : str , namespace : str , database : AIOEngine = Depends ( get_odm_session ), namespaces : List [ Namespace ] = Depends ( get_allowed_namespaces ), username : str = Depends ( get_username ) ) Delete a node from the database. If there are multiple nodes with the same name, the first found node will be deleted. If there are no nodes with the name, this will fail. Raises HTTPException : Raises exception if multiple nodes were found HTTPException : Raises exception if node was not found HTTPException : Raises exception if namespace not found or access denied Returns Str : Node deleted","title":"Node"},{"location":"public/api/node/#_1","text":"","title":""},{"location":"public/api/node/#stop_node","text":"source . stop_node ( namespace : str , node_name : str , redis_client : Redis = Depends ( get_redis_client ), database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), namespaces : List [ Namespace ] = Depends ( get_allowed_namespaces ) )","title":"stop_node"},{"location":"public/api/node/#node_metrics","text":"source . node_metrics ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : Redis = Depends ( get_redis_client ), namespaces : List [ str ] = Depends ( get_allowed_namespaces ), username : str = Depends ( get_username ) )","title":"node_metrics"},{"location":"public/api/node/#delete_node","text":"source . delete_node ( node_name : str , namespace : str , database : AIOEngine = Depends ( get_odm_session ), namespaces : List [ Namespace ] = Depends ( get_allowed_namespaces ), username : str = Depends ( get_username ) ) Delete a node from the database. If there are multiple nodes with the same name, the first found node will be deleted. If there are no nodes with the name, this will fail. Raises HTTPException : Raises exception if multiple nodes were found HTTPException : Raises exception if node was not found HTTPException : Raises exception if namespace not found or access denied Returns Str : Node deleted","title":"delete_node"},{"location":"public/api/task/","text":"active_tasks source . active_tasks ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : Redis = Depends ( get_redis_client ), username : str = Depends ( get_username ), search : str = '' , page : int = - 1 , page_size : int = - 1 ) tasks source . tasks ( namespace : str , username : str , search : str , database : AIOEngine , page : int = - 1 , page_size : int = - 1 , nodes : List [ NodeTasks ] = [] ) task_logs source . task_logs ( task_id : str , namespace : str , namespaces : List [ str ] = Depends ( get_allowed_namespaces ), username : str = Depends ( get_username ), page : int = - 1 , page_size : int = - 1 , database : AIOEngine = Depends ( get_odm_session ) )","title":"Task"},{"location":"public/api/task/#_1","text":"","title":""},{"location":"public/api/task/#active_tasks","text":"source . active_tasks ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : Redis = Depends ( get_redis_client ), username : str = Depends ( get_username ), search : str = '' , page : int = - 1 , page_size : int = - 1 )","title":"active_tasks"},{"location":"public/api/task/#tasks","text":"source . tasks ( namespace : str , username : str , search : str , database : AIOEngine , page : int = - 1 , page_size : int = - 1 , nodes : List [ NodeTasks ] = [] )","title":"tasks"},{"location":"public/api/task/#task_logs","text":"source . task_logs ( task_id : str , namespace : str , namespaces : List [ str ] = Depends ( get_allowed_namespaces ), username : str = Depends ( get_username ), page : int = - 1 , page_size : int = - 1 , database : AIOEngine = Depends ( get_odm_session ) )","title":"task_logs"},{"location":"public/api/task_control/","text":"new_task source . new_task ( namespace : str , task_name : str , json_body : NewTaskRequest = Body ( ... ), username : str = Depends ( get_username ), rabbitmq_url : str = Depends ( get_rabbitmq_url ), database : AIOEngine = Depends ( get_odm_session ) )","title":"Task control"},{"location":"public/api/task_control/#_1","text":"","title":""},{"location":"public/api/task_control/#new_task","text":"source . new_task ( namespace : str , task_name : str , json_body : NewTaskRequest = Body ( ... ), username : str = Depends ( get_username ), rabbitmq_url : str = Depends ( get_rabbitmq_url ), database : AIOEngine = Depends ( get_odm_session ) )","title":"new_task"},{"location":"public/api/workflow/","text":"workflows source . workflows ( namespace : str , namespaces : List [ str ] = Depends ( get_allowed_namespaces_even_disabled ), database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), search : str = '' , page : int = - 1 , page_size : int = - 1 , sort_by : str = '' , sort_order : str = '' , begin : str = '' , end : str = '' ) workflow_tasks source . workflow_tasks ( workflow_id : str , namespace : str , database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), page : int = - 1 , page_size : int = - 1 ) workflow_status source . workflow_status ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), namespaces : List [ str ] = Depends ( get_allowed_namespaces_even_disabled ), workflow_id : List [ str ] = Query ([]), username : str = Depends ( get_username ) ) workflow_metrics source . workflow_metrics ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), namespaces : List [ str ] = Depends ( get_allowed_namespaces_even_disabled ), username : str = Depends ( get_username ) ) delete_workflow_logs source . delete_workflow_logs ( workflow_id : str , force : bool = Query ( False ), database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ) ) workflow_logs source . workflow_logs ( workflow_id : str , database : AIOEngine = Depends ( get_odm_session ), page : int = - 1 , page_size : int = - 1 , namespaces : List [ str ] = Depends ( get_allowed_namespaces ), username : str = Depends ( get_username ) )","title":"Workflow"},{"location":"public/api/workflow/#_1","text":"","title":""},{"location":"public/api/workflow/#workflows","text":"source . workflows ( namespace : str , namespaces : List [ str ] = Depends ( get_allowed_namespaces_even_disabled ), database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), search : str = '' , page : int = - 1 , page_size : int = - 1 , sort_by : str = '' , sort_order : str = '' , begin : str = '' , end : str = '' )","title":"workflows"},{"location":"public/api/workflow/#workflow_tasks","text":"source . workflow_tasks ( workflow_id : str , namespace : str , database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), page : int = - 1 , page_size : int = - 1 )","title":"workflow_tasks"},{"location":"public/api/workflow/#workflow_status","text":"source . workflow_status ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), namespaces : List [ str ] = Depends ( get_allowed_namespaces_even_disabled ), workflow_id : List [ str ] = Query ([]), username : str = Depends ( get_username ) )","title":"workflow_status"},{"location":"public/api/workflow/#workflow_metrics","text":"source . workflow_metrics ( namespace : str , database : AIOEngine = Depends ( get_odm_session ), namespaces : List [ str ] = Depends ( get_allowed_namespaces_even_disabled ), username : str = Depends ( get_username ) )","title":"workflow_metrics"},{"location":"public/api/workflow/#delete_workflow_logs","text":"source . delete_workflow_logs ( workflow_id : str , force : bool = Query ( False ), database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ) )","title":"delete_workflow_logs"},{"location":"public/api/workflow/#workflow_logs","text":"source . workflow_logs ( workflow_id : str , database : AIOEngine = Depends ( get_odm_session ), page : int = - 1 , page_size : int = - 1 , namespaces : List [ str ] = Depends ( get_allowed_namespaces ), username : str = Depends ( get_username ) )","title":"workflow_logs"},{"location":"public/api/workflow_control/","text":"stop_workflow source . stop_workflow ( namespace : str , workflow_id : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : StrictRedis = Depends ( get_redis_client ), username : str = Depends ( get_username ) ) API Endpoint to stop a running workflow Args namespace (str) : Namespace workflow_id (str) : ID of the selected workflow database (AIOEngine, optional) : Database Object. Defaults to Depends(get_odm_session). redis_client (StrictRedis, optional) : Redis Client. Defaults to Depends(get_redis_client). username (str, optional) : Username. Defaults to Depends(get_username). Raises HTTPException : Raises exception if workflow already stopped HTTPException : Raises exception if namespace does not exists or user has no access. Returns Str : Workflow stopped abort_workflow source . abort_workflow ( namespace : str , workflow_id : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : StrictRedis = Depends ( get_redis_client ), username : str = Depends ( get_username ) ) API Endpoint to abort a running workflow Args namespace (str) : Namespace workflow_id (str) : ID of the selected workflow database (AIOEngine, optional) : Database Object. Defaults to Depends(get_odm_session). redis_client (StrictRedis, optional) : Redis Client. Defaults to Depends(get_redis_client). username (str, optional) : Username. Defaults to Depends(get_username). Raises HTTPException : Raises exception if workflow already stopped HTTPException : Raises exception if namespace does not exists or user has no access. Returns Str : Workflow aborted restart_workflow source . restart_workflow ( namespace : str , workflow_id : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : StrictRedis = Depends ( get_redis_client ), username : str = Depends ( get_username ), rabbitmq_url : str = Depends ( get_rabbitmq_url ), namespace_obj : Namespace = Depends ( get_allowed_namespace ) ) API endpoint to abort a workflow and start it again Args namespace (str) : Namespace workflow_id (str) : Workflow ID database (AIOEngine, optional) : Database Object. Defaults to Depends(get_odm_session). redis_client (StrictRedis, optional) : Redis Client. Defaults to Depends(get_redis_client). username (str, optional) : Username. Defaults to Depends(get_username). rabbitmq_url (str, optional) : RabbitMQ Url. Defaults to Depends(get_rabbitmq_url). namespace_obj (Namespace, optional) : Namespace Object to check if user has access to it. Defaults to Depends(get_allowed_namespace). Raises HTTPException : Raises exception if workflow could not be restarted HTTPException : Raises exception if workflow already stopped HTTPException : Raises exception if namespace does not exist or user has no access. Returns Str : Workflow restarted","title":"Workflow control"},{"location":"public/api/workflow_control/#_1","text":"","title":""},{"location":"public/api/workflow_control/#stop_workflow","text":"source . stop_workflow ( namespace : str , workflow_id : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : StrictRedis = Depends ( get_redis_client ), username : str = Depends ( get_username ) ) API Endpoint to stop a running workflow Args namespace (str) : Namespace workflow_id (str) : ID of the selected workflow database (AIOEngine, optional) : Database Object. Defaults to Depends(get_odm_session). redis_client (StrictRedis, optional) : Redis Client. Defaults to Depends(get_redis_client). username (str, optional) : Username. Defaults to Depends(get_username). Raises HTTPException : Raises exception if workflow already stopped HTTPException : Raises exception if namespace does not exists or user has no access. Returns Str : Workflow stopped","title":"stop_workflow"},{"location":"public/api/workflow_control/#abort_workflow","text":"source . abort_workflow ( namespace : str , workflow_id : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : StrictRedis = Depends ( get_redis_client ), username : str = Depends ( get_username ) ) API Endpoint to abort a running workflow Args namespace (str) : Namespace workflow_id (str) : ID of the selected workflow database (AIOEngine, optional) : Database Object. Defaults to Depends(get_odm_session). redis_client (StrictRedis, optional) : Redis Client. Defaults to Depends(get_redis_client). username (str, optional) : Username. Defaults to Depends(get_username). Raises HTTPException : Raises exception if workflow already stopped HTTPException : Raises exception if namespace does not exists or user has no access. Returns Str : Workflow aborted","title":"abort_workflow"},{"location":"public/api/workflow_control/#restart_workflow","text":"source . restart_workflow ( namespace : str , workflow_id : str , database : AIOEngine = Depends ( get_odm_session ), redis_client : StrictRedis = Depends ( get_redis_client ), username : str = Depends ( get_username ), rabbitmq_url : str = Depends ( get_rabbitmq_url ), namespace_obj : Namespace = Depends ( get_allowed_namespace ) ) API endpoint to abort a workflow and start it again Args namespace (str) : Namespace workflow_id (str) : Workflow ID database (AIOEngine, optional) : Database Object. Defaults to Depends(get_odm_session). redis_client (StrictRedis, optional) : Redis Client. Defaults to Depends(get_redis_client). username (str, optional) : Username. Defaults to Depends(get_username). rabbitmq_url (str, optional) : RabbitMQ Url. Defaults to Depends(get_rabbitmq_url). namespace_obj (Namespace, optional) : Namespace Object to check if user has access to it. Defaults to Depends(get_allowed_namespace). Raises HTTPException : Raises exception if workflow could not be restarted HTTPException : Raises exception if workflow already stopped HTTPException : Raises exception if namespace does not exist or user has no access. Returns Str : Workflow restarted","title":"restart_workflow"},{"location":"public/api/auth/login/","text":"login source . login ( request : Request , response : Response , credentials : LoginRequest , database : AIOEngine = Depends ( get_odm_session ), server_secret : str = Depends ( get_server_secret ) ) create_tokens source . create_tokens ( hostname : str , credentials : LoginRequest , server_secret : str , user_information : UserInformation , database : AIOEngine , response : Response ) Creates access & refresh token, set them as cookies and return them additionally Args hostname (str) : Rest API Hostname credentials (LoginRequest) : Login POST body (username, password, scopes) server_secret (str) : Server secret used for jwt signage and jwe encryption user_information (UserInformation) : Result from authentication API request database (AIOEngine) : Database session (odmantic) response (Response) : FastAPI Response object Returns Dict : Access token, Refresh token get_user_information source . get_user_information ( credentials : Credentials , idp_config : IdpDomainConfig ) perform_user_information_request source . perform_user_information_request ( credentials : Credentials , headers : dict , client : AsyncClient , url : str ) get_scopes source . get_scopes ( scopes : List [ str ] = [], roles : List [ IdpRoleConfig ] = [] ) create_token source . create_token ( hostname : str , credentials : LoginRequest , server_secret : str , user_information : UserInformation , username : str , database : AIOEngine , jti : str ) create_refresh_token source . create_refresh_token ( database , hostname : str , server_secret : str , user_information : UserInformation , credentials : LoginRequest , jti : str )","title":"Login"},{"location":"public/api/auth/login/#_1","text":"","title":""},{"location":"public/api/auth/login/#login","text":"source . login ( request : Request , response : Response , credentials : LoginRequest , database : AIOEngine = Depends ( get_odm_session ), server_secret : str = Depends ( get_server_secret ) )","title":"login"},{"location":"public/api/auth/login/#create_tokens","text":"source . create_tokens ( hostname : str , credentials : LoginRequest , server_secret : str , user_information : UserInformation , database : AIOEngine , response : Response ) Creates access & refresh token, set them as cookies and return them additionally Args hostname (str) : Rest API Hostname credentials (LoginRequest) : Login POST body (username, password, scopes) server_secret (str) : Server secret used for jwt signage and jwe encryption user_information (UserInformation) : Result from authentication API request database (AIOEngine) : Database session (odmantic) response (Response) : FastAPI Response object Returns Dict : Access token, Refresh token","title":"create_tokens"},{"location":"public/api/auth/login/#get_user_information","text":"source . get_user_information ( credentials : Credentials , idp_config : IdpDomainConfig )","title":"get_user_information"},{"location":"public/api/auth/login/#perform_user_information_request","text":"source . perform_user_information_request ( credentials : Credentials , headers : dict , client : AsyncClient , url : str )","title":"perform_user_information_request"},{"location":"public/api/auth/login/#get_scopes","text":"source . get_scopes ( scopes : List [ str ] = [], roles : List [ IdpRoleConfig ] = [] )","title":"get_scopes"},{"location":"public/api/auth/login/#create_token","text":"source . create_token ( hostname : str , credentials : LoginRequest , server_secret : str , user_information : UserInformation , username : str , database : AIOEngine , jti : str )","title":"create_token"},{"location":"public/api/auth/login/#create_refresh_token","text":"source . create_refresh_token ( database , hostname : str , server_secret : str , user_information : UserInformation , credentials : LoginRequest , jti : str )","title":"create_refresh_token"},{"location":"public/api/auth/logout/","text":"logout source . logout ( response : Response , database : AIOEngine = Depends ( get_odm_session ), token : Token = Depends ( get_token ) )","title":"Logout"},{"location":"public/api/auth/logout/#_1","text":"","title":""},{"location":"public/api/auth/logout/#logout","text":"source . logout ( response : Response , database : AIOEngine = Depends ( get_odm_session ), token : Token = Depends ( get_token ) )","title":"logout"},{"location":"public/api/auth/refresh_token/","text":"access_token_from_refresh_token source . access_token_from_refresh_token ( bearer_token : HTTPAuthorizationCredentials = Depends ( HTTPBearer ()), server_secret : str = Depends ( get_server_secret ), database : AIOEngine = Depends ( get_odm_session ), hostname : str = Depends ( get_hostname ) ) create_token source . create_token ( database : AIOEngine , token : CredentialsToken , hostname : str , key : str ) find_refresh_token source . find_refresh_token ( database : AIOEngine , jti : str )","title":"Refresh token"},{"location":"public/api/auth/refresh_token/#_1","text":"","title":""},{"location":"public/api/auth/refresh_token/#access_token_from_refresh_token","text":"source . access_token_from_refresh_token ( bearer_token : HTTPAuthorizationCredentials = Depends ( HTTPBearer ()), server_secret : str = Depends ( get_server_secret ), database : AIOEngine = Depends ( get_odm_session ), hostname : str = Depends ( get_hostname ) )","title":"access_token_from_refresh_token"},{"location":"public/api/auth/refresh_token/#create_token","text":"source . create_token ( database : AIOEngine , token : CredentialsToken , hostname : str , key : str )","title":"create_token"},{"location":"public/api/auth/refresh_token/#find_refresh_token","text":"source . find_refresh_token ( database : AIOEngine , jti : str )","title":"find_refresh_token"},{"location":"public/api/auth/user_profile/","text":"get_scopes_by_config source . get_scopes_by_config ( database : AIOEngine , idp_config : IdpDomainConfig , user_information : UserInformation ) perform_user_information_request_impersonated source . perform_user_information_request_impersonated ( idp_credentials : Credentials , user_ids : List [ str ], headers : dict , client : AsyncClient , url : str ) get_user_information_impersonated source . get_user_information_impersonated ( idp_credentials : Credentials , idp_config : IdpDomainConfig , user_ids : List [ str ] ) get_user_information_by_config source . get_user_information_by_config ( database : AIOEngine , idp_credentials : Credentials , idp_config : IdpDomainConfig , username : str ) user_profile source . user_profile ( token : Token = Depends ( get_token ), database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), idp_credentials : Credentials = Depends ( get_idp_credentials ) )","title":"User profile"},{"location":"public/api/auth/user_profile/#_1","text":"","title":""},{"location":"public/api/auth/user_profile/#get_scopes_by_config","text":"source . get_scopes_by_config ( database : AIOEngine , idp_config : IdpDomainConfig , user_information : UserInformation )","title":"get_scopes_by_config"},{"location":"public/api/auth/user_profile/#perform_user_information_request_impersonated","text":"source . perform_user_information_request_impersonated ( idp_credentials : Credentials , user_ids : List [ str ], headers : dict , client : AsyncClient , url : str )","title":"perform_user_information_request_impersonated"},{"location":"public/api/auth/user_profile/#get_user_information_impersonated","text":"source . get_user_information_impersonated ( idp_credentials : Credentials , idp_config : IdpDomainConfig , user_ids : List [ str ] )","title":"get_user_information_impersonated"},{"location":"public/api/auth/user_profile/#get_user_information_by_config","text":"source . get_user_information_by_config ( database : AIOEngine , idp_credentials : Credentials , idp_config : IdpDomainConfig , username : str )","title":"get_user_information_by_config"},{"location":"public/api/auth/user_profile/#user_profile","text":"source . user_profile ( token : Token = Depends ( get_token ), database : AIOEngine = Depends ( get_odm_session ), username : str = Depends ( get_username ), idp_credentials : Credentials = Depends ( get_idp_credentials ) )","title":"user_profile"}]}